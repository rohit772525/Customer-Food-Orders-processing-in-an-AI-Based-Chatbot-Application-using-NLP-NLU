{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLU_r8zDFQd3",
        "outputId": "c34d1323-cc62-45ab-e754-6faa21720dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'Tandoori Chicken' and 'butter naan': 1.00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cda1577ed365>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Word Similarity Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_word_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordsim353.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Word Similarity Evaluation:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mevaluate_word_pairs\u001b[0;34m(self, pairs, delimiter, encoding, restrict_vocab, case_insensitive, dummy4unknown)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msimilarity_gold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1507\u001b[0m                 \u001b[0;34mf\"No valid similarity judgements found in {pairs}: either invalid format or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m                 \u001b[0;34mf\"all are out-of-vocabulary in {self}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No valid similarity judgements found in wordsim353.tsv: either invalid format or all are out-of-vocabulary in KeyedVectors<vector_size=100, 179 keys>"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import logging\n",
        "\n",
        "def train_word2vec_model(sentences, vector_size=100, window=5, min_count=1, workers=4, epochs=100):\n",
        "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "    model = Word2Vec(sentences,\n",
        "                     vector_size=vector_size,\n",
        "                     window=window,\n",
        "                     min_count=min_count,\n",
        "                     workers=workers,\n",
        "                     epochs=epochs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample dataset\n",
        "    sentences = [  ['Do', 'you', 'serve', 'burgers', 'with', 'cheese', 'here?'],\n",
        "    ['I', 'want', 'misal_pav', 'with', 'a', 'side', 'of', 'roasted', 'peanuts', 'for', 'added', 'crunch?'],\n",
        "    ['One', 'order', 'of', 'Tandoori Chicken', 'with', 'tangy tamarind chutney'],\n",
        "    ['I', 'will', 'Tandoori Chicken', 'with', 'a', 'butter naan'],\n",
        "    ['I', 'want', 'to', 'enjoy', 'the', 'flavors', 'of', 'Tandoori Chicken', 'with', 'dal makhani'],\n",
        "    ['I', 'want', 'to', 'enjoy', 'the', 'Pani Puri', 'with', 'a', 'side', 'of', 'spicy chutney'],\n",
        "    ['Can', 'I', 'have', 'some', 'Pani Puri', 'with', 'extra', 'sweet', 'tamarind water,', 'please?'],\n",
        "    ['May', 'I', 'have', 'a', 'serving', 'of', 'Pani Puri', 'with', 'some', 'sev', 'on', 'top?'],\n",
        "    ['Please', 'serve', 'me', 'a', 'plate', 'of', 'Veg Pulao', 'with', 'raita', 'and', 'papad'],\n",
        "    [\"I'll\", 'have', 'a', 'Chicken Shawarma'],\n",
        "    [\"I'll\", 'have', 'a', 'Veg Biryani'],\n",
        "    ['Can', 'I', 'get', 'a', 'Caesar Salad?'],\n",
        "    ['One', 'plate', 'of', 'Chana Masala', 'with', 'Bhature,', 'please.'],\n",
        "    [\"I'd\", 'love', 'to', 'try', 'your', 'Paneer Tikka'],\n",
        "    ['I', 'like', 'to', 'savor', 'some', 'Palak Paneer', 'with', 'garlic naan', 'and', 'a', 'side', 'of', 'raita.'],\n",
        "    ['I', 'like', 'to', 'savor', 'some', 'Palak Paneer', 'with', 'garlic naan', 'and', 'a', 'side', 'of', 'raita.'],\n",
        "    ['Please', 'bring', 'me', 'a', 'plate', 'of', 'Aloo Paratha', 'with', 'juice', 'and', 'a', 'dollop', 'of', 'butter.'],\n",
        "    ['I', 'would', 'like', 'some', 'Hyderabadi Biryani', 'with', 'Mirchi', 'ka', 'Salan', 'and', 'cucumber', 'salad.'],\n",
        "    ['Can', 'I', 'get', 'a', 'plate', 'of', 'Rajma Chawal', 'with', 'papad', 'and', 'some', 'onion', 'salad?'],\n",
        "    ['I', 'want', 'to', 'enjoy', 'the', 'flavors', 'of', 'Malai Kofta', 'with', 'butter naan', 'and', 'a', 'refreshing', 'glass', 'of', 'Lassi.'],\n",
        "    ['I', 'want', 'to', 'try', 'your', 'Gulab Jamun', 'with', 'a', 'scoop', 'of', 'vanilla ice cream'],\n",
        "    ['Make', 'me', 'a', 'Vada Pav', 'extra', 'spicy', 'and', 'serve', 'it', 'with', 'green chilies?'],\n",
        "    ['I', 'like', 'to', 'try', 'your', 'Kaju Katli', 'with', 'a', 'touch', 'of', 'saffron.'],\n",
        "    ['I', 'want', 'Rasgulla', 'with', 'some', 'rose', 'syrup.'],\n",
        "    ['I', 'like', 'Vada Pav,', 'a', 'popular', 'Maharashtrian', 'street', 'food.'],\n",
        "    ['Please', 'bring', 'me', 'a', 'plate', 'of', 'Misal', 'Pav,', 'a', 'spicy', 'and', 'flavorful', 'Maharashtrian', 'dish.'],\n",
        "    ['I', 'craving', 'for', 'some', 'Puran Poli,', 'a', 'delicious', 'sweet', 'flatbread', 'from', 'Maharashtra.'],\n",
        "    ['Can', 'I', 'get', 'a', 'serving', 'of', 'Pav Bhaji,', 'a', 'mouthwatering', 'Maharashtrian', 'fast', 'food?'],\n",
        "    ['Please', 'serve', 'me', 'a', 'bowl', 'of', 'Bharli Vangi,', 'a', 'stuffed', 'eggplant', 'delicacy', 'from', 'Maharashtra.'],\n",
        "    ['One', 'plate', 'of', 'Sabudana Khichdi', 'a', 'popular', 'fasting', 'dish', 'in', 'Maharashtra,', 'please.'],\n",
        "    ['I', 'want', 'to', 'enjoy', 'the', 'flavors', 'of', 'Kothimbir Vadi', 'a', 'savory', 'cilantro', 'snack', 'from', 'Maharashtra.'],\n",
        "    ['Can', 'you', 'make', 'my', 'Puran Poli', 'extra', 'sweet', 'and', 'serve', 'it', 'with', 'a', 'dollop', 'of', 'ghee?'],\n",
        "    ['I', 'have', 'a', 'plate', 'of', 'Bombil', 'Fry,', 'a', 'crispy', 'and', 'delicious', 'Maharashtrian', 'fish', 'preparation.'],\n",
        "    ['Please', 'bring', 'me', 'a', 'bowl', 'of', 'Solkadhi,', 'a', 'traditional', 'Maharashtrian', 'drink', 'made', 'with', 'coconut', 'milk', 'and', 'kokum.'],\n",
        "    ['I', 'am', 'in', 'mood', 'for', 'some', 'Kanda Bhaji', 'a', 'popular', 'onion', 'fritter', 'from', 'Maharashtra.'],\n",
        "    ['I', 'want', 'to', 'enjoy', 'the', 'flavors', 'of', 'Shrikhand', 'a', 'popular', 'sweet', 'dish', 'from', 'Maharashtra.'],\n",
        "    ['Please', 'serve', 'me', 'a', 'plate', 'of', 'Kanda Bhaji', 'a', 'popular', 'Maharashtrian', 'snack.'],\n",
        "    ['I', 'want', 'to', 'enjoy', 'the', 'flavors', 'of', 'Batata Vada,', 'a', 'spicy', 'potato fritter.'],\n",
        "    ['I', 'craving', 'for', 'some', 'Dhokla', 'a', 'famous', 'Gujarati', 'snack.'],\n",
        "    ['Can', 'I', 'get', 'a', 'serving', 'of', 'Undhiyu', 'a', 'traditional', 'Gujarati', 'mixed', 'vegetable', 'dish?'],\n",
        "    ['I', 'like', 'to', 'order', 'some', 'Vegetable', 'Manchurian', 'a', 'popular', 'Indo Chinese', 'dish.'],\n",
        "    ['One', 'plate', 'of', 'Kutchi Dabeli', 'a', 'famous', 'Gujarati', 'street', 'food,', 'please.'],\n",
        "    ['Please', 'bring', 'me', 'a', 'plate', 'of', 'Rava Idli', 'with', 'coconut chutney'],\n",
        "    ['One', 'plate', 'of', 'Mini', 'Idli', 'with', 'sambar', 'please.'],\n",
        "    ['Can', 'you', 'make', 'my', 'Poha', 'with', 'extra', 'peanuts?'],\n",
        "    ['I', 'want', 'to', 'try', 'your', 'Vangi Poha', 'with', 'eggplant'],\n",
        "    ['One', 'plate', 'of', 'Poha Dhokla', 'please.'],\n",
        "\n",
        "    ]\n",
        "\n",
        "    # Train the Word2Vec model\n",
        "    model = train_word2vec_model(sentences)\n",
        "\n",
        "    # Check similarity between specific words\n",
        "    word1 = 'Tandoori Chicken'\n",
        "    word2 = 'butter naan'\n",
        "    similarity = model.wv.similarity(word1, word2)\n",
        "    print(f\"Similarity between '{word1}' and '{word2}': {similarity:.2f}\")\n",
        "\n",
        "    # Word Similarity Evaluation\n",
        "    similarity_scores = model.wv.evaluate_word_pairs('wordsim353.tsv')\n",
        "    print(\"Word Similarity Evaluation:\")\n",
        "    print(similarity_scores)\n",
        "\n",
        "    # Word Analogy Evaluation\n",
        "    analogy_scores = model.wv.evaluate_word_analogies('questions-words.txt')\n",
        "    print(\"Word Analogy Evaluation:\")\n",
        "    print(analogy_scores)\n",
        "\n",
        "    model_filename = \"word2vec_model.bin\"\n",
        "    model.save(model_filename)\n",
        "    print(f\"Word2Vec model has been saved to '{model_filename}'.\")\n"
      ]
    }
  ]
}